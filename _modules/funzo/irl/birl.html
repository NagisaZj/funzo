

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>funzo.irl.birl &mdash; funzo 0.1.0 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../../../_static/gallery.css" type="text/css" />
  
    <link rel="stylesheet" href="../../../_static/fix_rtd.css" type="text/css" />
  

  
    <link rel="top" title="funzo 0.1.0 documentation" href="../../../index.html"/>
        <link rel="up" title="Module code" href="../../index.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> funzo
          

          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../user/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user/usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user/contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user/development.html">Development</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/models.html"><code class="docutils literal"><span class="pre">funzo.models</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/irl.html"><code class="docutils literal"><span class="pre">funzo.irl</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/domains.html"><code class="docutils literal"><span class="pre">funzo.domains</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/planners.html"><code class="docutils literal"><span class="pre">funzo.planners</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/representation.html"><code class="docutils literal"><span class="pre">funzo.representation</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/utils.html"><code class="docutils literal"><span class="pre">funzo.utils</span></code></a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../../index.html">funzo</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../index.html">Docs</a> &raquo;</li>
      
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      
    <li>funzo.irl.birl</li>
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for funzo.irl.birl</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Bayesian inverse reinforcement learning</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>

<span class="kn">import</span> <span class="nn">six</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">abstractmethod</span><span class="p">,</span> <span class="n">ABCMeta</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="kn">import</span> <span class="nb">range</span><span class="p">,</span> <span class="nb">zip</span>

<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
<span class="kn">from</span> <span class="nn">scipy.misc</span> <span class="kn">import</span> <span class="n">logsumexp</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multivariate_normal</span>

<span class="kn">from</span> <span class="nn">.base</span> <span class="kn">import</span> <span class="n">IRLSolver</span>
<span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">..utils.validation</span> <span class="kn">import</span> <span class="n">check_random_state</span>
<span class="kn">from</span> <span class="nn">..utils.data_structures</span> <span class="kn">import</span> <span class="n">Trace</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;BIRL&#39;</span><span class="p">]</span>


<div class="viewcode-block" id="BIRL"><a class="viewcode-back" href="../../../modules/irl.html#funzo.irl.BIRL">[docs]</a><span class="k">class</span> <span class="nc">BIRL</span><span class="p">(</span><span class="n">IRLSolver</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Bayesian IRL algorithm</span>

<span class="sd">    BIRL algorithm that seeks to find a reward function underlying a set of</span>
<span class="sd">    expert demonstrations by computing the posterior of the reward distribution</span>
<span class="sd">    :math:`p(r | \Xi)`.</span>

<span class="sd">    These algorithms typically summarize the distribution by taking a single</span>
<span class="sd">    value such as the mean.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    planner : a callable</span>
<span class="sd">        A planner for MDP e.g. policy iteration as a callable</span>
<span class="sd">    prior : :class:`RewardPrior` or derivative object</span>
<span class="sd">        Reward prior callable object</span>
<span class="sd">    inference : str, optional (default=&#39;PW&#39;)</span>
<span class="sd">        Inference procedure [&#39;PW&#39;, &#39;MPW&#39;, &#39;MAP&#39;]</span>
<span class="sd">    beta : float, optional (default=0.7)</span>
<span class="sd">        Expert optimality parameter for the reward likelihood term in the</span>
<span class="sd">        product of exponential distributions</span>
<span class="sd">    random_state : :class:`numpy.RandomState`, optional (default: None)</span>
<span class="sd">        Random number generation seed control</span>


<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    _prior : :class:`RewardPrior` or derivative object</span>
<span class="sd">        Reference to the reward prior callable object</span>
<span class="sd">    _beta : float, optional (default=0.9)</span>
<span class="sd">        Expert optimality parameter for the reward likelihood term in the</span>
<span class="sd">        product of exponential distributions</span>
<span class="sd">    _rng : :class:`numpy.RandomState`</span>
<span class="sd">        Random number generator</span>
<span class="sd">    _inference : str</span>
<span class="sd">        Inference procedure</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">planner</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">inference</span><span class="o">=</span><span class="s1">&#39;PW&#39;</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                 <span class="n">burn_ratio</span><span class="o">=</span><span class="mf">0.27</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BIRL</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">planner</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_prior</span> <span class="o">=</span> <span class="n">prior</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_beta</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inference</span> <span class="o">=</span> <span class="n">inference</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

        <span class="k">if</span> <span class="mi">0</span> <span class="o">&gt;=</span> <span class="n">max_iter</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;No. of iterations must be in (0, inf)&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inference</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;PW&#39;</span><span class="p">,</span> <span class="s1">&#39;MPW&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="mf">0.0</span> <span class="o">&gt;</span> <span class="n">burn_ratio</span> <span class="o">&gt;=</span> <span class="mf">1.0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;burn ratio must be in [0, 1)&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_burn</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_iter</span> <span class="o">*</span> <span class="n">burn_ratio</span> <span class="o">/</span> <span class="mf">100.0</span><span class="p">)</span>

        <span class="k">if</span> <span class="mf">0.0</span> <span class="o">&gt;=</span> <span class="n">delta</span> <span class="o">&gt;</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Reward steps (delta) must be in (0, 1)&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_delta</span> <span class="o">=</span> <span class="n">delta</span>

<div class="viewcode-block" id="BIRL.solve"><a class="viewcode-back" href="../../../modules/irl.html#funzo.irl.BIRL.solve">[docs]</a>    <span class="k">def</span> <span class="nf">solve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">demos</span><span class="p">,</span> <span class="n">mdp</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Solve the BIRL problem &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">mdp</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;BIRL requires an MDP model&#39;</span><span class="p">)</span>

        <span class="n">v</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="s1">&#39;r_mean&#39;</span><span class="p">,</span> <span class="s1">&#39;sample&#39;</span><span class="p">,</span> <span class="s1">&#39;a_ratio&#39;</span><span class="p">]</span>
        <span class="n">trace</span> <span class="o">=</span> <span class="n">Trace</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">save_interval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_iter</span><span class="o">//</span><span class="mi">2</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inference</span> <span class="o">==</span> <span class="s1">&#39;PW&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_policy_walk</span><span class="p">(</span><span class="n">mdp</span><span class="p">,</span> <span class="n">demos</span><span class="p">,</span> <span class="n">trace</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inference</span> <span class="o">==</span> <span class="s1">&#39;MAP&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_find_map</span><span class="p">(</span><span class="n">mdp</span><span class="p">,</span> <span class="n">demos</span><span class="p">,</span> <span class="n">trace</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_policy_walk</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mdp</span><span class="p">,</span> <span class="n">demos</span><span class="p">,</span> <span class="n">trace</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Find the reward using PolicyWalk &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_proposal</span> <span class="o">=</span> <span class="n">PolicyWalkProposal</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">mdp</span><span class="o">.</span><span class="n">reward</span><span class="p">),</span>
                                            <span class="n">delta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_delta</span><span class="p">)</span>

        <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_reward</span><span class="p">(</span><span class="n">mdp</span><span class="o">.</span><span class="n">reward</span><span class="o">.</span><span class="n">rmax</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">mdp</span><span class="o">.</span><span class="n">reward</span><span class="p">))</span>
        <span class="n">plan_r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_solve_mdp</span><span class="p">(</span><span class="n">mdp</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>

        <span class="n">r_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_iter</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;PolicyWalk&#39;</span><span class="p">):</span>
            <span class="n">r_new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_proposal</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
            <span class="n">plan_r_new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_solve_mdp</span><span class="p">(</span><span class="n">mdp</span><span class="p">,</span> <span class="n">r_new</span><span class="p">,</span> <span class="n">plan_r</span><span class="p">[</span><span class="s1">&#39;V&#39;</span><span class="p">],</span> <span class="n">plan_r</span><span class="p">[</span><span class="s1">&#39;pi&#39;</span><span class="p">])</span>
            <span class="n">p_accept</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_acceptance_ratio</span><span class="p">(</span><span class="n">mdp</span><span class="p">,</span> <span class="n">demos</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">r_new</span><span class="p">,</span>
                                              <span class="n">plan_r</span><span class="p">[</span><span class="s1">&#39;Q&#39;</span><span class="p">],</span> <span class="n">plan_r_new</span><span class="p">[</span><span class="s1">&#39;Q&#39;</span><span class="p">])</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&lt;</span> <span class="nb">min</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">p_accept</span><span class="p">])</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_cooling</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
                <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">r_new</span><span class="p">)</span>
                <span class="n">plan_r</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">plan_r_new</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_burn</span><span class="p">:</span>
                <span class="n">r_mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iterative_mean</span><span class="p">(</span><span class="n">r_mean</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">step</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">_burn</span><span class="p">)</span>
                <span class="n">trace</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">r_mean</span><span class="o">=</span><span class="n">r_mean</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="n">r_new</span><span class="p">,</span>
                             <span class="n">a_ratio</span><span class="o">=</span><span class="n">p_accept</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">trace</span>

    <span class="k">def</span> <span class="nf">_find_map</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mdp</span><span class="p">,</span> <span class="n">demos</span><span class="p">,</span> <span class="n">trace</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Find the reward by direct MAP estimation &quot;&quot;&quot;</span>

        <span class="n">trace</span><span class="o">.</span><span class="n">add_vars</span><span class="p">([</span><span class="s1">&#39;f&#39;</span><span class="p">,</span> <span class="s1">&#39;r_map&#39;</span><span class="p">])</span>

        <span class="n">rmax</span> <span class="o">=</span> <span class="n">mdp</span><span class="o">.</span><span class="n">reward</span><span class="o">.</span><span class="n">rmax</span>
        <span class="n">bounds</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">((</span><span class="o">-</span><span class="n">rmax</span><span class="p">,</span> <span class="n">rmax</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mdp</span><span class="o">.</span><span class="n">reward</span><span class="p">)))</span>

        <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_reward</span><span class="p">(</span><span class="n">mdp</span><span class="o">.</span><span class="n">reward</span><span class="o">.</span><span class="n">rmax</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">mdp</span><span class="o">.</span><span class="n">reward</span><span class="p">))</span>

        <span class="k">def</span> <span class="nf">_callback_optimization</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot; Callback to catch the optimization progress &quot;&quot;&quot;</span>
            <span class="n">trace</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="n">r</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_mdp</span> <span class="o">=</span> <span class="n">mdp</span>  <span class="c1"># temporary HACK</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_demos</span> <span class="o">=</span> <span class="n">demos</span>

        <span class="c1"># r is argmax_r p(D|r)p(r)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_posterior</span><span class="p">,</span>
                       <span class="n">x0</span><span class="o">=</span><span class="n">r</span><span class="p">,</span>
                       <span class="n">method</span><span class="o">=</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span>
                       <span class="n">jac</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                       <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
                       <span class="n">callback</span><span class="o">=</span><span class="n">_callback_optimization</span><span class="p">)</span>

        <span class="n">trace</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="n">r_map</span><span class="o">=</span><span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="n">res</span><span class="o">.</span><span class="n">fun</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">trace</span>

    <span class="k">def</span> <span class="nf">_initialize_reward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rmax</span><span class="p">,</span> <span class="n">rdim</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Initialize a reward vector using the prior &quot;&quot;&quot;</span>
        <span class="n">candidates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">rmax</span><span class="p">,</span> <span class="n">rmax</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">_delta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_delta</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">rdim</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rdim</span><span class="p">):</span>
            <span class="n">r</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">candidates</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">r</span>

    <span class="k">def</span> <span class="nf">_acceptance_ratio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mdp</span><span class="p">,</span> <span class="n">demos</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">r_new</span><span class="p">,</span> <span class="n">Q_r</span><span class="p">,</span> <span class="n">Q_r_new</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Compute the PolicyWalk acceptance ratio &quot;&quot;&quot;</span>
        <span class="n">ratio</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">true_divide</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_prior</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">r_new</span><span class="p">),</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">_prior</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">r</span><span class="p">)))</span>
        <span class="k">for</span> <span class="n">traj</span> <span class="ow">in</span> <span class="n">demos</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">traj</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">for</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span> <span class="ow">in</span> <span class="n">traj</span><span class="p">:</span>
                    <span class="n">rr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_beta</span> <span class="o">*</span> <span class="n">Q_r</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">s</span><span class="p">])</span> <span class="o">/</span>\
                            <span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_beta</span> <span class="o">*</span> <span class="n">Q_r</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">s</span><span class="p">])</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">mdp</span><span class="o">.</span><span class="n">A</span><span class="p">)</span>
                    <span class="n">rr_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_beta</span> <span class="o">*</span> <span class="n">Q_r_new</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">s</span><span class="p">])</span> <span class="o">/</span>\
                        <span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_beta</span> <span class="o">*</span> <span class="n">Q_r_new</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">s</span><span class="p">])</span>
                            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">mdp</span><span class="o">.</span><span class="n">A</span><span class="p">)</span>

                    <span class="n">ratio</span> <span class="o">*=</span> <span class="n">rr_new</span> <span class="o">/</span> <span class="n">rr</span>
        <span class="k">return</span> <span class="n">ratio</span>

    <span class="k">def</span> <span class="nf">_log_posterior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Reward posterior distribution (unnormalized) &quot;&quot;&quot;</span>
        <span class="n">plan_r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_solve_mdp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mdp</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
        <span class="n">llk</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span><span class="p">(</span><span class="n">plan_r</span><span class="p">[</span><span class="s1">&#39;Q&#39;</span><span class="p">])</span>
        <span class="n">lp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_prior</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">llk</span> <span class="o">+</span> <span class="n">lp</span>

    <span class="k">def</span> <span class="nf">_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Q_r</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Evaluate the log likelihood of the demonstrations w.r.t reward &quot;&quot;&quot;</span>
        <span class="n">llk</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">M</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_demos</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">traj</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_demos</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">traj</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">H</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">traj</span><span class="p">)</span>
                <span class="n">alpha_H</span> <span class="o">=</span> <span class="mf">0.0</span>
                <span class="n">beta_H</span> <span class="o">=</span> <span class="mf">0.0</span>
                <span class="k">for</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span> <span class="ow">in</span> <span class="n">traj</span><span class="p">:</span>
                    <span class="n">alpha_H</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beta</span> <span class="o">*</span> <span class="n">Q_r</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">s</span><span class="p">]</span>
                    <span class="n">beta_Hs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_beta</span> <span class="o">*</span> <span class="n">Q_r</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">s</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mdp</span><span class="o">.</span><span class="n">A</span><span class="p">]</span>
                    <span class="n">beta_H</span> <span class="o">+=</span> <span class="n">logsumexp</span><span class="p">(</span><span class="n">beta_Hs</span><span class="p">)</span>

                <span class="n">llk</span> <span class="o">+=</span> <span class="p">(</span><span class="n">alpha_H</span> <span class="o">-</span> <span class="n">beta_H</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">H</span><span class="p">)</span>
        <span class="n">llk</span> <span class="o">/=</span> <span class="nb">float</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">llk</span>

    <span class="k">def</span> <span class="nf">_log_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Compute log prior probability &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prior</span><span class="o">.</span><span class="n">log_p</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_iterative_mean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r_mean</span><span class="p">,</span> <span class="n">r_new</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Compute the iterative mean of the reward &quot;&quot;&quot;</span>
        <span class="n">r_mean</span> <span class="o">=</span> <span class="p">[((</span><span class="n">step</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">step</span><span class="p">))</span> <span class="o">*</span>
                  <span class="n">r_m</span> <span class="o">+</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">step</span> <span class="o">*</span> <span class="n">r</span> <span class="k">for</span> <span class="n">r_m</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">r_mean</span><span class="p">,</span> <span class="n">r_new</span><span class="p">)]</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">r_mean</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_cooling</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Tempering &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mf">5.0</span> <span class="o">+</span> <span class="n">step</span> <span class="o">/</span> <span class="mf">50.0</span></div>


<span class="c1">########################################################################</span>
<span class="c1"># MCMC proposals</span>
<span class="c1">########################################################################</span>


<div class="viewcode-block" id="Proposal"><a class="viewcode-back" href="../../../modules/irl.html#funzo.irl.Proposal">[docs]</a><span class="k">class</span> <span class="nc">Proposal</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Proposal for MCMC sampling &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>

    <span class="nd">@abstractmethod</span>
<div class="viewcode-block" id="Proposal.step"><a class="viewcode-back" href="../../../modules/irl.html#funzo.irl.Proposal.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">location</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Take a single MCMC chain step &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;abstract&#39;</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="PolicyWalkProposal"><a class="viewcode-back" href="../../../modules/irl.html#funzo.irl.PolicyWalkProposal">[docs]</a><span class="k">class</span> <span class="nc">PolicyWalkProposal</span><span class="p">(</span><span class="n">Proposal</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; PolicyWalk MCMC proposal</span>

<span class="sd">    Sampling in the hypercube with limits [-rmax, rmax]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">rmax</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PolicyWalkProposal</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delta</span> <span class="o">=</span> <span class="n">delta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rmax</span> <span class="o">=</span> <span class="n">rmax</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

<div class="viewcode-block" id="PolicyWalkProposal.step"><a class="viewcode-back" href="../../../modules/irl.html#funzo.irl.PolicyWalkProposal.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">location</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Take a single MCMC chain step</span>

<span class="sd">        PolicyWalk takes steps in the grid defined by,</span>

<span class="sd">        .. math::</span>

<span class="sd">            \mathbb{R}^{|R|} / \delta</span>

<span class="sd">        where :math:`|R|` is the dimension of the reward space, which can get</span>
<span class="sd">        very large. In this case a lot of samples are needed before the MCMC</span>
<span class="sd">        chain converges.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">location</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">delta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">delta</span><span class="p">])</span>
        <span class="n">i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
        <span class="k">if</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">rmax</span> <span class="o">&lt;=</span> <span class="n">sample</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="n">d</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rmax</span><span class="p">:</span>
            <span class="n">sample</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">d</span>
        <span class="k">return</span> <span class="n">sample</span></div></div>


<span class="c1">########################################################################</span>
<span class="c1"># Reward Priors</span>
<span class="c1"># ######################################################################</span>


<div class="viewcode-block" id="RewardPrior"><a class="viewcode-back" href="../../../modules/irl.html#funzo.irl.RewardPrior">[docs]</a><span class="k">class</span> <span class="nc">RewardPrior</span><span class="p">(</span><span class="n">six</span><span class="o">.</span><span class="n">with_metaclass</span><span class="p">(</span><span class="n">ABCMeta</span><span class="p">,</span> <span class="n">Model</span><span class="p">)):</span>
    <span class="sd">&quot;&quot;&quot; Reward prior interface</span>

<span class="sd">    The reward prior summarizes information about the reward distribution that</span>
<span class="sd">    is available before running the algorithm, i.e. all the relevant domain</span>
<span class="sd">    knowledge.</span>

<span class="sd">    These distributions are multivariate, i.e. samples are vectors</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="k">if</span> <span class="mi">0</span> <span class="o">&gt;</span> <span class="n">dim</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Reward space dimension must be positive&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dim</span> <span class="o">=</span> <span class="n">dim</span>

    <span class="nd">@abstractmethod</span>
<div class="viewcode-block" id="RewardPrior.pdf"><a class="viewcode-back" href="../../../modules/irl.html#funzo.irl.RewardPrior.pdf">[docs]</a>    <span class="k">def</span> <span class="nf">pdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Evaluate the pdf of the reward prior distribution</span>

<span class="sd">        .. math::</span>

<span class="sd">            p(r \in A) = \int_A f d\mu</span>

<span class="sd">        for any :math:`A \in \mathcal{A}`, given some measurable space :math:`(\mathcal{X}, \mathcal{A})` and a measure :math:`\mu`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method&#39;</span><span class="p">)</span></div>

    <span class="nd">@abstractmethod</span>
<div class="viewcode-block" id="RewardPrior.log_p"><a class="viewcode-back" href="../../../modules/irl.html#funzo.irl.RewardPrior.log_p">[docs]</a>    <span class="k">def</span> <span class="nf">log_p</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Evaluate the logpdf of the reward prior distribution &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method&#39;</span><span class="p">)</span></div>

    <span class="nd">@abstractmethod</span>
<div class="viewcode-block" id="RewardPrior.sample"><a class="viewcode-back" href="../../../modules/irl.html#funzo.irl.RewardPrior.sample">[docs]</a>    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Generate a sample from the reward prior distribution</span>

<span class="sd">        .. math::</span>

<span class="sd">            r \sim f_{\\theta}</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method&#39;</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="GaussianRewardPrior"><a class="viewcode-back" href="../../../modules/irl.html#funzo.irl.GaussianRewardPrior">[docs]</a><span class="k">class</span> <span class="nc">GaussianRewardPrior</span><span class="p">(</span><span class="n">RewardPrior</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Gaussian reward prior &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GaussianRewardPrior</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dim</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dim</span><span class="p">)</span> <span class="o">*</span> <span class="n">mean</span>
        <span class="c1"># TODO - allow different covariance shapes, and full mean vectors</span>

<div class="viewcode-block" id="GaussianRewardPrior.pdf"><a class="viewcode-back" href="../../../modules/irl.html#funzo.irl.GaussianRewardPrior.pdf">[docs]</a>    <span class="k">def</span> <span class="nf">pdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Evaluate the pdf of the reward prior distribution &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_mu</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_cov</span><span class="p">)</span></div>

<div class="viewcode-block" id="GaussianRewardPrior.log_p"><a class="viewcode-back" href="../../../modules/irl.html#funzo.irl.GaussianRewardPrior.log_p">[docs]</a>    <span class="k">def</span> <span class="nf">log_p</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Evaluate the logpdf of the reward prior distribution &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_mu</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_cov</span><span class="p">)</span></div>

<div class="viewcode-block" id="GaussianRewardPrior.sample"><a class="viewcode-back" href="../../../modules/irl.html#funzo.irl.GaussianRewardPrior.sample">[docs]</a>    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Generate a sample from the reward prior distribution</span>

<span class="sd">        .. math::</span>

<span class="sd">            r \sim \mathcal{N}(\mathbf{\mu}, \mathbf{\Sigma})</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_mu</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_cov</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2015–2016, Billy Okal.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'0.1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>